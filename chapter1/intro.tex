Quantum computing exploits non-classical phenomena described by quantum
mechanics, such as entanglement and superposition, to perform computations,
 often with considerable speedup with respect to classical computers.

Both theory and practical implementations have attracted considerable research
efforts in the last forty years. Different physical systems may be used to represent
quantum information, ranging from the state of
particles or molecules, e.g. trapped ions~\cite{pogorelov_compact_2021}, to
small superconducting circuits~\cite{clarke_superconducting_2008}. Despite the
variety of solutions, realizability of large scale quantum machines is still an
open question, since the impact of negative phenomena, such as decoherence,
increase exponentially with state size, thus requiring more resources allocated to
perform error-correction. However, private enterprises started
either selling machines or providing cloud access to them, proving it is actually 
an emergent technology, with increasing interest among the scientific community.

The theory of quantum computing started with the development of the quantum
turing machine model~\cite{benioff_quantum_1982}, but the most common model in use today is the\textit{ quantum circuit model}, based on qubits, quantum gates and
measurement operations. A \textit{qubit} is the basic unit of quantum information, a two-state quantum mechanical system. All these models rely on the idea that the state is a set of qubits on which the programmer can apply different transformations. The main models are thus inherently stateful and imperative. 
Regardless of the physical implementation, two states of the elementary quantum system are denoted as the $\kz$ and $\ko$ states.
The analogy with bits is obvious. A first difference with respect to classical computation is that the state of a qubit can also be a linear combination of $\kz$ and $\ko$, called a \textit{superposition}. In accordance with linear algebra, $\kz$ and $\ko$ form a \textit{basis} of the state space, known as the computational basis. Examples of qubits in superposition are the two denoted as $\kpl$ or $\km$, that are both combinations of $\kz$ and $\ko$. Interestingly, also $\kz$ and $\ko$ can be expressed as a linear combination of $\kpl$ and $\km$, and in fact $\kpl$ and $\km$ are called the \textit{diagonal basis} of the state space. 

Quantum computing theory is mainly developed along two axis: algorithms and
protocols. Even though quantum computers obey the Church-Turing
thesis~\cite{nielsen_quantum_2010}, algorithms have been found with more
than polynomial speedup over classical counterparts, for example Shor's algorithm for
factorization~\cite{shor_algorithms_1994} and the HHL algorithm for solving
linear systems of equations~\cite{harrow_quantum_2009}.

Quantum protocols, in particular cryptography-related protocols, have been  one of the first application 
of quantum theory to computer science. Due to lower physical
requirements with respect to algorithms, various protocols have been implemented
in real world contexts, also with large-scale commercially available physical implementations.
The prototipical case is the BB84 Quantum Key Distribution
protocol \cite{shor_simple_2000}, that has been proven unconditionally secure. As for algorithms, most protocols can be implemented with just classical control and classical communication. However some protocols, such as Quantum Key
Distribution~\cite{poppe_practical_2004} and Quantum Leader
Election~\cite{tani_exact_2012}, also require \textit{quantum communication} (i.e. sending and receiving qubits).


Correctness proof are available for some quantum algorithms, but there is no systematic approach for verifying protocols and their application in larger systems.
As it is well known, correctness of classical communication protocols is already hard to prove at design stage, with notorious examples of vulnerabilities discovered for protocols previously considered to be secure. This is more-so true for quantum protocols, which must resist both quantum and classical attackers.


Process calculi are a formal model to represent concurrent systems. They are based on an "algebraic" way to compose simple processes in more complex one, and specifically target synchronization and communication among them.
Process calculi have been successful in modeling classical concurrent systems featuring also non-determinism and probability. This formal model provides systematic solutions for analyzing and verifying the correctness of new systems and protocols. We expect the same will hold also in the quantum case, which still turns out to be a challenging setting.


To model quantum protocols, a process calculus needs to handle both classical and quantum communication at once, and must take into account the peculiar rules of quantum computations. Due to the properties of quantum systems, quantum information better fits the imperative stateful paradigm, so the state must be kept alongside the process. A result that complicates the definition of quantum communication is the "No-Cloning Theorem", stating that qubits cannot be copied. For this reason, once a qubit is sent the sender cannot use it anymore.
Besides, qubits cannot be directly "observed", or measured, without losing some information. When measured in a basis, in fact, a qubit in superposition collapses to one of the two basis states in a probabilistic way.
Finally, a quantum process calculus must also deal with \textit{entangled qubits}, i.e. qubits that cannot be described separately, one at a time, but must be considered as a whole compound system, even when they are stored in physically distant locations.

Of all the proposed models, none has emerged as a universally accepted standard. Our objective is to address the extension of classical process calculi to the quantum world. For this we will compare the different proposals, with a foundational approach aiming at identifying the best notion of behavioural equivalence. We propose a novel calculus named Linear qCCS, for which we consider different definitions of bisimilarity.
Defining an appropriate bisimilarity is in fact the first step towards temporal logics, model checking and all the other tools available for the classical models.


\subsection*{A lacking standard notion of behavioural equivalence}

There is a number of proposals of quantum process calculi in the literature, often with different syntax, semantics and behavioural equivalences, even if they all model the same systems and the same protocols \cite{lalireProcessAlgebraicApproach2004, gayCommunicatingQuantumProcesses2005, fengProbabilisticBisimulationsQuantum2007, yingAlgebraQuantumProcesses2010, wangProbabilisticProcessAlgebra2019}. Of all these, the most established and developed are \textbf{QPAlg} \cite{lalireProcessAlgebraicApproach2004}, \textbf{CQP} \cite{gayCommunicatingQuantumProcesses2005} and \textbf{qCCS} \cite{fengProbabilisticBisimulationsQuantum2007}. They all differ in  a number of minor "classical" details, that unfortunately make the calculi difficult to compare: some are inspired by $\pi$-calculus, some by CCS; some employ strong bisimilarity while others employ weak or branching bisimilarity; some apply Larsen-Skou probabilistic bisimilarity \cite{larsenBisimulationProbabilisticTesting1991}, some apply Segala probabilistic bisimilarity \cite{segalaProbabilisticSimulationsProbabilistic1994}.

More importantly, the proposed languages treat quantum information in different ways, leading to different notions of behavioural equivalence. 
A typical example are the two processes 
\[P = c?x.H(x).\nil \qquad Q = c?x.X(x).\nil\]
(here written in the syntax of qCCS). Both processes receive a qubit on channel $c$ ($c?x$), modify it ($H(x) / X(x)$), and then terminate ($\nil$). The first process applies an Hadamard transformation, while the second applies a $X$ transformation, resulting in a different quantum states. The discriminating question is, should $P$ and $Q$ be considered bisimilar? That is, do $P$ and $Q$ express the same observable behaviour, and are therefore indistinguishable? 

The answer depends on the exact notion of \textit{observable property}, which varies between the proposed calculi. In QPAlg and CQP, a qubit is observable only when it is sent, as it is the case for "classical" value passing or name passing calculi. In this setting, $P$ and $Q$ are indeed bisimilar, because the qubit they modified is not visible to an external observer. In qCCS instead, after a process has terminated, the qubits it has operated on become observable. Qwhen $P$ and $Q$ reach $\nil$, they leave the qubit in two different states, and this sufficies to refutate bisimilarity in qCCS. This discrepancy is due to a sort of "ambiguity", present in the syntax of all the calculi proposed up to now, on what happens to the qubits after the process termination.
 
 Another crucial notion when defining behavioural equivalence is how to compare qubit values. In a classical process calculus, we can say that $c!0.\nil$ is not bisimilar to $c!1.\nil$ because they send two different \textit{values} ($c!0 / c!1$) before terminating. In a quantum setting it is difficult to talk about the value of a single qubit, because the qubit may be entangled.  Take for example the two processes 
 \[R = Set_{\Phi}(q_1, q_2).c!q_1.c!q_2 \qquad 
   S = Set_{\Psi}(q_1, q_2).c!q_1.c!q_2\]
where $R$ and $S$ set the value of the two qubits ($Set_{\Phi}(q_1, q_2) / Set_{\Psi}(q_1, q_2)$) to different entangled states ($\ket{\Phi} / \ket{\Psi}$), and send them.\footnote{for example, we could take $\Phi = \oost\ket{00} + \oost\ket{11}$ and $\Psi = \oost\ket{01} + \oost\ket{10}$, as it will be explained in the next chapter} 
Quantum theory tells us that entangled states are distinguishable only when taken as a whole, as a compound 2-qubit system. In the presence of entanglement, one cannot describe the state of just qubit $q_1$ without losing some information. For this reason, if the values of qbits are considered only one at the time, we lose some discriminating power allowed by quantum theory.

On the opposite side, quantum theory comes also with negative results about distinguishability of probabilistic mixtures (i.e. distributions) of quantum states. Also in this case, the capability of the observer to discriminate between different entities must be considered carefully, and is addressed or ignored in different calculi.
 
Summarizing, different calculi deal with quantum features in different ways. In QPAlg the value of a sent qubit ignores entanglement, and so the two processes $R$ and $S$ above are deemed bisimilar. In qCCS, the "environment", i.e. the state of all visible qubits, is considered when comparing two processes, thus $R$ and $S$ are not bisimilar. In CQP there is a similar notion of environment, but takes into account also the limited discriminating capability of an external observer for probabilistic mixtures of quantum states, naturally arising upon measurements.
 
\subsection*{Linear qCCS: a unifying approach}
The main objective of this thesis is to introduce Linear qCCS, and use it to investigate the different notions of behavioural equivalence of quantum systems. Linear qCCS (lqCCS) is designed to resolve the ambiguities and discrepancies of the previous proposals, and to identify the most adequate behavioural equivalence relation.

lqCCS is a (asynchronous) version on qCCS, equipped with a type system that grants linear communication of qubits. Indeed, due to the No-Cloning Theorem, once a qubit is sent on a channel, the sender process cannot use it anymore. In lqCCS each qubit used by a process must be sent \textit{exactly} once. This means that the two processes $P$ and $Q$ of the previous section are not well typed in lqCCS, while $P', Q', P'', Q''$ are.
\begin{align*}
P' &= c?x.H(x).c!x &  Q' &= c?x.X(x).c!x \\
P'' &= c?x.H(x).discard(x) &  Q'' &= c?x.X(x).discard(x)
\end{align*}
The $discard(q)$ action is typed the same as a send action $c!q$, but when it comes to bisimilarity, $q$ is not considered a visible qubit.\footnote{For example, in (standard) qCCS $discard(q)$ can be implemented with channel restrictions, like $c!q\setminus c$.}

Thanks to its linear type system, lqCCS forces the designer to make an explicit choice on what happens to the qubits at the end of a computation. By writing processes like $P'$ or $Q'$, the qubit are made visible, thus the two processes are not bisimilar. When writing processes like $P''$ and $Q''$, the qubit is not visible, and the processes are bisimilar. Note that when deciding to use a discard or a send action, we can switch between a behaviour à la QPAlg/CQP (where $P$ is bisimilar to $Q$), and à la qCCS (where they are not).

Having solved the ambiguity on when a qubit should be visible or not, the only relevant detail is how to describe the quantum state. This allows us to compare directly the different bisimilarity relations presented in the literature, and to determine which are the crucial  quantum-related details that makes a difference when defining a bisimilarity.  

Since there  is no unique and accepted notion of "observable property" of quantum processes, each definition of labeled bisimilarity has to make some assumption on which are the properties to be checked when comparing two processes. Instead we opted for a (probabilistic) \textit{saturated bisimilarity}, which in turn is based on an Unlabeled Transition System, and embodies both bisimilarity and contextual equivalence. Two processes $P$ and $Q$ are saturated bisimilar if they express the same atomic observable properties (called \textit{barbs}), and when put inside the same context they evolve to bisimilar processes. As barbs we take the property of "being able to send on a specific channel", which  is a standard choice for barbs. Notice that in this way we made no a-priori assumption on quantum values representation. In saturated bisimilarity, in fact, it is in charge of the contexts to distinguish different values. For example, $P'$ and $Q'$ seen before are distinguished by a context that receives the modified qubit, measures it and is able to tell the difference.

A technical advantage of such saturated bisimilarity is that, instead of adding requirements to guarantee that the labelled bisimilarity is a congruence, we start from a relation that is a congruence by definition, and explore which are the properties that can be observed by an arbitrary context.


\subsection*{The unexpected inadequacy of probabilistic bisimilarity}

With probabilistic saturated bisimilarity we can recover the same (labelled) bisimilarity notion of qCCS, but not the one presented in the latest works on CQP. The main difference between qCCS and CQP bisimilarity is in the treatment of measurement operators and the resulting probabilistic behaviour.

Consider the two processes 
\[P = c?x.M_{01}(x).c!x \qquad Q = c?x.M_\pm(x).c!x\]
Both processes receive a qubit, measure it ($M_{01}(x) / M_{\pm}(x)$) and then send the measured qubit. Note that the measurements are of two different kind. As it will be clear later, this causes the resulting state of the sent qubits to differ. $P$ measures the qubit in the computational basis, so will send two possible qubits, $\kz$ or $\ko$, each with a certain probability. $Q$ measures in the diagonal basis, so will send two possible qubits, $+$ and $-$, each with a certain probability. There is an input for which $P$ will evolve in a symmetric \textit{distribution} of states, i.e. will send a qubit with state $\kz$ with probability $0.5$, or a qubit with state $\ko$ with probability $0.5$. Similarly, with the same input state, $Q$ will evolve in a symmetric distribution of sending $\kpl$ and $\km$.

When dealing with distributions the usual notion of  probabilistic bisimilarity says that two distribution are bisimilar when they assign the same probability to bisimilar processes. So, according to this definition, the processes $P$ and $Q$ are not bisimilar in qCCS and the same holds for probabilistic saturated bisimilarity in lqCCS.

Quantum theory, however, tells that it is not possible to distinguish a source $S_P$ sending half of the time $\kz$ and half of the time $\ko$ from a source $S_Q$ sending half of the time $\kpl$ and half of the time $\km$. This interesting property is due to the inherent limitations of the observer, which, to discriminate the two sources, can only try to perform measurements. For each chosen measurement, the obtained probabilistic distributions coincides. An an example, assume we measure the qubits from $S_P$ in the computational basis, the result will be half of the time $\kz$ and half of the time $\ko$, as the measurement in the computational basis does nothing on a qubit already in the computational basis. Similarly, when measuring a qubit coming from $S_Q$, a $\kpl$ qubit would decay in $\kz$ or $\ko$, each with the same probability, and the same happens for $\km$. Hence, the two sources appear the same for an external observer performing the measurement on the computational basis, and the same happens for all the basis. 
In accordance with this peculiar quantum feature, in CQP the processes $P$ and $Q$ are considered bisimilar. This is obtained by
defining observable properties directly on distributions, instead of simply lifting bisimilarty of processes.

We identify the well established notion of Larsen-Skou \cite{larsenBisimulationProbabilisticTesting1991} probabilistic bisimulation  as the cause of this undesired behaviour of qCCS, and propose a novel notion of \textit{quantum saturated bisimilarity} that represents more correctly the observable properties of probabilistic distribution of quantum states. To obtain this result, we model the undishtingishability results of quantum theory as an equivalence relation between distributions of states and processes.  
%Thanks to this equivalence relation, we relax the conditions of saturated bisimilarity, asking that when two distribution $\Delta$ and $\Theta$ are bisimilar, they are not necessarily Larsen-Skou bisimilar, but there are some equivalent distribution $\Delta'$ and $\Theta'$ that are Larsen-Skou bisimilar.
Thanks to this equivalence relation, we relax the conditions of saturated bisimilarity, allowing to change the "actual" distribution with an equivalent one to match the behaviour of a bisimilar distribution.
 Using quantum saturated bisimilarity we can recover many results obtained for CQP bisimilarity, although in a different and arguably more standard transition system.
 
 \subsection*{A minimal quantum process calculus}
 
The usual notion of probabilistic bisimilarity seems not well suited to treat distributions of configurations containing quantum values, even if quantum systems have some obvious probabilistic features. Given that a well established notion of behavioural equivalence for quantum processes has not emerged yet, we have decided to pursue a foundational approach, investigating the topic on a Minimal Quantum Process Algebra (mQPA).
Working with a minimal process algebra allows us to omit all the irrelevant classical details, and to target the quantum aspects in isolation.
In addition to a minimal set of classical features, mQPA has unitary transformations (representing the evolution of isolated quantum states),
and a novel operator for combining processes, called projective sum.
Similarly to what happens in a probabilistic process algebra, where a probabilistic sum operator produces a distribution
of states, the projective sum produces a quantum distribution of states, i.e. a probabilistic distribution that depends on the quantum value
to be measured.
The state of the qubits is not kept along the process, and is not updated in a small-step fashion as the process evolves.
On the contrary, the operational semantics of a mQPA is defined as implicitly parametric on the quantum state.
This approach is peculiar, as it resemble none of the current proposals (to the best of our knowledge).
A bisimilarity then is defined in a fairly standard way, and is shown to work well with the previous problematic examples.
 